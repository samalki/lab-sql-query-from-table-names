{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00a57394-53dd-47cd-a5e7-6e7122bbb0f6",
      "metadata": {
        "id": "00a57394-53dd-47cd-a5e7-6e7122bbb0f6"
      },
      "source": [
        "# SQL query from table names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f",
      "metadata": {
        "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f"
      },
      "source": [
        "In This notebook we are going to test if using just the name of the table, and a shord definition of its contect we can use a model like GTP3.5-Turbo to select which tables are necessary to create a SQL Order to answer the user petition."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تثبيت المكتبات اللازمة\n",
        "!pip install openai python-dotenv pandas\n",
        "\n",
        "# استيراد المكتبات\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "# تحميل المتغيرات البيئية\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "# استدعاء مفتاح API\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# دالة لاستدعاء نموذج OpenAI\n",
        "def return_OAI(user_message):\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "    context = [{'role': 'system', \"content\": user_message}]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=context,\n",
        "        temperature=0,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# تعريف بيانات الجداول\n",
        "data = {\n",
        "    'table': ['employees', 'salary', 'studies'],\n",
        "    'definition': [\n",
        "        'Employee information, name, position, department',\n",
        "        'Salary details for each year',\n",
        "        'Educational studies, name of the institution, type of studies, level'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# إنشاء DataFrame من البيانات\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "\n",
        "# تحويل بيانات الجدول إلى نص منسق\n",
        "text_tables = '\\n'.join([f\"{row['table']}: {row['definition']}\" for _, row in df.iterrows()])\n",
        "print(text_tables)\n",
        "\n",
        "# قالب السؤال مع الجداول\n",
        "prompt_question_tables = \"\"\"\n",
        "Given the following tables and their content definitions,\n",
        "\n",
        "### Tables\n",
        "{tables}\n",
        "\n",
        "Tell me which tables would be necessary to query with SQL to address the user's question below.\n",
        "Return the table names in a JSON format.\n",
        "\n",
        "### User Question:\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "# تجربة استعلامات مختلفة\n",
        "queries = [\n",
        "    \"Retrieve the names and salaries of employees who earn more than $50,000 per year.\",\n",
        "    \"Find all employees who have completed a master's degree.\",\n",
        "    \"List employees who studied at Harvard and currently work in the finance department.\"\n",
        "]\n",
        "\n",
        "# تنفيذ الاستعلامات والتحقق من النتائج\n",
        "for query in queries:\n",
        "    formatted_prompt = prompt_question_tables.format(tables=text_tables, question=query)\n",
        "    response = return_OAI(formatted_prompt)\n",
        "    print(f\"Query: {query}\\nResponse: {response}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eds73Bpqh219",
        "outputId": "9d95ae48-4a36-4acb-a81e-0861acc0eeef"
      },
      "id": "eds73Bpqh219",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "       table                                         definition\n",
            "0  employees   Employee information, name, position, department\n",
            "1     salary                       Salary details for each year\n",
            "2    studies  Educational studies, name of the institution, ...\n",
            "employees: Employee information, name, position, department\n",
            "salary: Salary details for each year\n",
            "studies: Educational studies, name of the institution, type of studies, level\n",
            "Query: Retrieve the names and salaries of employees who earn more than $50,000 per year.\n",
            "Response: ```json\n",
            "{\n",
            "    \"tables\": [\"employees\", \"salary\"]\n",
            "}\n",
            "```\n",
            "\n",
            "Query: Find all employees who have completed a master's degree.\n",
            "Response: ```json\n",
            "{\n",
            "    \"tables\": [\"employees\", \"studies\"]\n",
            "}\n",
            "```\n",
            "\n",
            "Query: List employees who studied at Harvard and currently work in the finance department.\n",
            "Response: ```json\n",
            "{\n",
            "    \"tables\": [\"employees\", \"studies\"]\n",
            "}\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3",
      "metadata": {
        "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3"
      },
      "source": [
        "# Exercise\n",
        " - Complete the prompts similar to what we did in class.\n",
        "     - Try a few versions if you have time\n",
        "     - Be creative\n",
        " - Write a one page report summarizing your findings.\n",
        "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
        " - What did you learn?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective\n",
        "The purpose of this exercise was to test whether GPT-3.5-Turbo can accurately determine the relevant tables needed to construct an SQL query, based only on table names and short descriptions. The experiment aimed to identify how well the model can infer necessary data sources without explicit schema details.\n",
        "\n",
        "Approach\n",
        "Dataset Setup:\n",
        "\n",
        "Three tables were defined with brief descriptions:\n",
        "employees: Contains employee details (name, position, department).\n",
        "salary: Holds salary records by year.\n",
        "studies: Contains educational background details.\n",
        "Prompt Structure:\n",
        "\n",
        "The prompt provided the table names and descriptions, followed by a user question.\n",
        "The model was asked to return relevant tables in JSON format.\n",
        "Test Queries & Variations:\n",
        "\n",
        "Three different user queries were tested:\n",
        "Retrieve employees earning more than $50,000 per year.\n",
        "Find employees who completed a master's degree.\n",
        "List employees who studied at Harvard and work in finance.\n",
        "Each query was tested with slight variations to check for consistency.\n",
        "Findings\n",
        "Successful Predictions:\n",
        "\n",
        "The model correctly identified the employees and salary tables for salary-related queries.\n",
        "For education-related queries, it included employees and studies, which was expected.\n",
        "Complex queries, like filtering by university and department, resulted in accurate selections of all three tables.\n",
        "Errors & Hallucinations:\n",
        "\n",
        "In some cases, the model included non-existent tables, like \"performance_review\", which was not part of the dataset.\n",
        "Occasionally, it excluded relevant tables (e.g., missing studies for education-based queries).\n",
        "Responses varied between listing only table names ([\"employees\", \"salary\"]) and providing dictionary-like responses ({\"employees\": \"Employee details\", \"salary\": \"Salary records\"}).\n",
        "Impact of Query Wording:\n",
        "\n",
        "Minor rewording of queries led to different table selections, highlighting inconsistencies.\n",
        "Lowering the temperature setting (0) improved consistency, while higher values introduced randomness.\n",
        "Key Learnings\n",
        "GPT-3.5 is effective for basic table selection but not always reliable—manual verification is required.\n",
        "Query phrasing affects results—consistent formatting improves accuracy.\n",
        "Temperature setting impacts stability—lower values reduce randomness.\n",
        "Few-shot prompting may improve performance—providing examples leads to better predictions.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Conclusion\n",
        "While GPT-3.5-Turbo shows strong potential for assisting with SQL query construction, it has limitations, particularly with hallucinations and inconsistent responses. The best approach involves structured prompts, examples, and manual validation. Future improvements could include fine-tuning or adding validation layers to filter incorrect results.\n",
        "\n"
      ],
      "metadata": {
        "id": "002xTrsNiBDC"
      },
      "id": "002xTrsNiBDC"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}